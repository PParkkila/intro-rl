\documentclass[12pt]{article}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{enumerate}
\usepackage{fancyvrb}
\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}
\usepackage{hyperref}
\usepackage{placeins}
\usepackage{tikz}
\usepackage{tikzsymbols}
\usepackage{todonotes}
\usepackage{bbm}
\usepackage{color}
\usepackage{mathrsfs}
\usepackage{minted}
\usepackage{enumitem}
\usepackage{soul} % for HL
\usepackage{color} % for HL

\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

% \renewcommand{\theenumi}{\roman{enumi}}
\newcommand{\rmn}[1]{{\textcolor{blue}{\bf [{\sc rmn:} #1]}}}
\DeclareMathOperator*{\argmax}{arg\,max}

\usetikzlibrary{positioning,calc}
%%%%%%%%%
\usepackage[most]{tcolorbox}
\newtcolorbox[]{solution}[1][]{%
    breakable,
    enhanced,
    colback=white,
    title=Solution,
    #1
}

\newtcolorbox[]{fillme}[1][]{%
    breakable,
    enhanced,
    colback=white,
    title=Fill me in,
    #1
}

\newcommand*{\E}{\mathbb{E}}
\newcommand*{\prob}{\mathbb{P}}
\newcommand*{\F}{\mathcal{F}}
\newtheorem{theorem}{Theorem}
\newtheorem{observation}{Observation}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}

%%%%%%%%%%

\date{Due February 19, 2024}
\author{\begin{fillme}[width=0.3\textwidth]
 Your name here.
\end{fillme}} % Fill in your name!

\title{ECE433/COS435 Introduction to RL\\
  Assignment 2: Imitation Learning\\
  Spring 2024\\
}

\begin{document}
    \maketitle
    \section*{Collaborators}
    \begin{fillme}
     Please fill in the names and NetIDs of your collaborators in this section.
    \end{fillme}

    \section*{Instructions}
    
    The details of the assignment are provided in the accompanying .ipynb file.
    You should use Google Colab to run the provided .ipynb file.
    However, note that \textbf{we will only grade your answers within this writeup.}
    As such, when submitting to Gradescope, \textbf{please include the requested answer/code block in the provide solution boxes for every problem within this TeX file.}
    Nevertheless, make sure to still attach your notebook/code with your submission, in addition to the compiled PDF.

    \clearpage
    
    \section*{Problem 1. Flap Like How Flappy Sr. Taught You! (AKA Implementing Behavioral Cloning)}
        \subsection*{(a) Policy Evaluation} 
            Paste the \textbf{entire cell} implementing policy evaluation below.
            \begin{solution}
                \begin{minted}[autogobble]{python}
# YOUR CODE HERE!
                \end{minted}
            \end{solution}

            \noindent
            Paste the \textbf{entire cell} for evaluating a policy that chooses actions uniformly at random below.
            \begin{solution}
                \begin{minted}[autogobble]{python}
# YOUR CODE HERE!
                \end{minted}
            \end{solution}

        \clearpage
        
        \subsection*{(b) Defining a Policy} 
            Paste the \textbf{entire cell} defining a policy class over discrete actions below.
            \begin{solution}
                \begin{minted}[autogobble]{python}
# YOUR CODE HERE!
                \end{minted}
            \end{solution}

        \clearpage
            
        \subsection*{(c) Setting Up Behavioral Cloning} 
            Paste the \textbf{entire cell} defining a behavioral cloning training loop below.
            \begin{solution}
                \begin{minted}[autogobble]{python}
# YOUR CODE HERE!
                \end{minted}
            \end{solution}

        \clearpage

        \subsection*{(d) Setting Up Behavioral Cloning} 
            Paste the \textbf{entire cell} applying behavioral cloning to \verb+flappy_sr_notes.mat+ below.
            \begin{solution}
                \begin{minted}[autogobble]{python}
# YOUR CODE HERE!
                \end{minted}
            \end{solution}

        \clearpage

    \section*{Problem 2: Floppy the Sloppy Ruins (?) the Day (AKA An Introduction to Filtered Behavioral Cloning)}
    
        \subsection*{(a) What is Left???} 
            Paste the \textbf{entire cell} applying behavioral cloning to \verb+vandalized_notes.mat+ below.
            \begin{solution}
                \begin{minted}[autogobble]{python}
# YOUR CODE HERE!
                \end{minted}
            \end{solution}

        \clearpage
        
        \subsection*{(b) Array of Hope???} 
            Paste the \textbf{entire cell} defining a reweighed behavioral cloning loss below.
            \begin{solution}
                \begin{minted}[autogobble]{python}
# YOUR CODE HERE!
                \end{minted}
            \end{solution}

            \noindent
            Paste the \textbf{entire cell} defining a training loop using the reweighed behavioral cloning loss below.
            \begin{solution}
                \begin{minted}[autogobble]{python}
# YOUR CODE HERE!
                \end{minted}
            \end{solution}

        \clearpage
            
        \subsection*{(c) Filtering Strategy I: Trajectory-Level Reweighing???} 
            Paste the \textbf{entire cell} implementing the trajectory-level reweighing scheme below.
            \begin{solution}
                \begin{minted}[autogobble]{python}
# YOUR CODE HERE!
                \end{minted}
            \end{solution}

            \noindent
            Paste the \textbf{entire cell} applying the reweighing scheme above to Filtered BC.
            \begin{solution}
                \begin{minted}[autogobble]{python}
# YOUR CODE HERE!
                \end{minted}
            \end{solution}

        \clearpage
        
        \subsection*{(d) Filtering Strategy II: Truncated Future Return???} 
            Paste the \textbf{entire cell} implementing the truncated future return reweighing scheme below.
            \begin{solution}
                \begin{minted}[autogobble]{python}
# YOUR CODE HERE!
                \end{minted}
            \end{solution}

            \noindent
            Paste the \textbf{entire cell} applying the reweighing scheme above to Filtered BC.
            \begin{solution}
                \begin{minted}[autogobble]{python}
# YOUR CODE HERE!
                \end{minted}
            \end{solution}

        \clearpage

    \section*{Problem 3: Short-Answer Questions}

        For this problem, we will ask you a few questions regarding the experiments you ran to hopefully further develop your intuition for BC/Filtered BC.
        Limit your answer to each part to 2--3 sentences.
        Note that these questions are found throughout Problem 2 in the provided \verb+.ipynb+ file.

        \vspace{1ex}
        
        \noindent
        1. What does the result of the experiment in Problem 2(a) tell you about running behavioral cloning on noisy/low-quality datasets? Intuitively, why does this happen? \newline 
        (Hint: Think about what the BC loss is optimizing.)
        \begin{solution}
            (Your answer here.)
        \end{solution}

        \noindent
        2. Why does the trajectory-level reweighing scheme in Problem 2(c) work? How does it affect what the BC loss is doing?
        \begin{solution}
            (Your answer here.)
        \end{solution}

        \noindent
        3. What is the effect of the temperature on the weighing scheme in Problem 2(c)? \newline
        (Hint: As a starting point, think about what happens to the softmax function as $\alpha \to 0$. To make it even easier to think about, consider applying the softmax to two fixed values $a, b$ with $a > b$ as you take this limit.)
        \begin{solution}
            (Your answer here.)
        \end{solution}

        \noindent
        4. One could consider a version of the reweighing scheme from Problem 2(c), where we remove the softmax and simply define the weight for $\tau_i$ as $R(\tau_i)$. While this may work in certain circumstances, can you think of some potential pitfalls of such a weighing scheme? \newline
        (Hint: Think about the values the reward function could take in all kinds of environments).
        \begin{solution}
            (Your answer here.)
        \end{solution}

        \noindent
        5. Let us explore the effect of the hyperparameter $T$ on the weighing scheme in Problem 2(d). Give a succinct description of the weights when $T = 1$. Do you expect this to work well in general? Why or why not?
        \begin{solution}
            (Your answer here.)
        \end{solution}
        
        \noindent
        6. Can you think of a reason why one can set $T$ in Problem 2(d) relatively small in Flappy Bird and still obtain decent performance?
        \begin{solution}
            (Your answer here.)
        \end{solution}
\end{document}
